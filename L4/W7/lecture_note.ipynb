{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI and Medicine (Optional Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI in Medicine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction Navigating the Intersections of AI and Medicine\n",
    "\n",
    "#### Key Drivers of AI Transformation in Healthcare:\n",
    "1. **Data Availability & Utilization**: Growth in healthcare data enables AI advancements.\n",
    "2. **Technological Advancements**: Tools like ChatGPT, MedPaLM, and generative AI reshape the field.\n",
    "3. **Public Opinion & Awareness**: Influence on AI’s development and acceptance in healthcare.\n",
    "\n",
    "#### Key Considerations for AI Development:\n",
    "- **Fairness & Transparency**: Critical for avoiding biases and ethical dilemmas.\n",
    "- **Metrics & Evaluation**: Necessary to assess AI tools effectively.\n",
    "- **Ethical Concerns**: Ensure AI does not reinforce stereotypes or inequities.\n",
    "\n",
    "#### Role of Regulation in AI for Healthcare:\n",
    "1. **Regulatory Environment**: Shapes AI's trajectory by enforcing legal standards and promoting transparency.\n",
    "2. **Compliance & Quality**: Ensures AI meets benchmarks and mitigates ethical risks.\n",
    "3. **Impact on AI Development**: Regulatory frameworks guide responsible use and innovation in healthcare.\n",
    "\n",
    "#### Focus Areas in AI for Healthcare:\n",
    "1. **Equity in Medicine**: AI must address disparities and not exacerbate inequities.\n",
    "2. **Generative AI**: Offers potential to enhance healthcare but poses safety challenges.\n",
    "3. **Critical Engagement**: Understand and question AI's impact in healthcare to ensure equitable outcomes.\n",
    "\n",
    "#### Conclusion:\n",
    "- **Comprehensive Understanding**: Critical to grasp the interaction of AI and healthcare.\n",
    "- **Skill Development**: Encourages critical thinking about AI's role in healthcare transformation.\n",
    "\n",
    "This summary emphasizes the evolution of AI in healthcare, its impact on equity, and the importance of ethical and regulatory considerations for responsible AI deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Life Cycle of AI\n",
    "\n",
    "#### Overview of the AI Lifecycle:\n",
    "1. **Data Creation**: \n",
    "   - Involves understanding how data is generated and its limitations.\n",
    "   - Unrepresentative datasets, particularly from academic medical records, can lead to biased algorithms, under-serving diverse populations.\n",
    "   - **Key Ethical Concern**: Lack of socioeconomic, geographic, and racial diversity in training data.\n",
    "\n",
    "2. **Data Acquisition**:\n",
    "   - AI developers gather data, but convenience often drives decisions, resulting in incomplete or inappropriate datasets.\n",
    "   - **Ethical Considerations**:\n",
    "     - Insufficient transparency in data procurement.\n",
    "     - Lack of detail on privacy protections and demographic representation.\n",
    "     - **Call for Action**: Introduce stricter regulatory and transparency requirements to ensure appropriate data usage.\n",
    "\n",
    "3. **Model Development**:\n",
    "   - Optimization decisions affect marginalized populations and can reinforce biases.\n",
    "   - Handling imbalanced datasets is crucial to ensure fairness in AI models.\n",
    "   - Techniques like oversampling/undersampling or using SMOT can address class imbalances.\n",
    "   - **Key Recommendation**: Standardized reporting criteria (e.g., MINIMAR) should be adopted for transparency in model development.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Emphasis is often placed on performance metrics, with limited focus on fairness and AI bias.\n",
    "   - There is a need for **comprehensive evaluation metrics** that assess models in real clinical environments.\n",
    "   - **Challenge**: Assessing AI’s impact in clinical workflows remains underexplored.\n",
    "\n",
    "5. **Model Deployment**:\n",
    "   - Few AI models progress to deployment, and information on success or failure is scarce.\n",
    "   - The lack of systematic reporting and incentives for deployment practices hinders understanding of ethical issues.\n",
    "   - **MLOps** principles (from agile and continuous improvement cultures in software development) can guide the lifecycle and improve implementation.\n",
    "   - **Generalizability**: \n",
    "     - Essential for AI model success across different settings (internal, temporal, external, and domain generalizability).\n",
    "     - Validation studies should be tailored to the specific clinical use case, with appropriate disclaimers.\n",
    "\n",
    "#### Ethical Implications Across the AI Lifecycle:\n",
    "- **Transparency, fairness, and bias** should be addressed collectively across all phases.\n",
    "- Neglecting these issues in any one phase can result in systemic harm.\n",
    "- **Regulatory Influence**: Expanded guidelines and frameworks are needed to ensure ethical AI development in healthcare, especially as models move from research to real-world applications.\n",
    "\n",
    "This summary captures the ethical challenges and best practices across the AI lifecycle, from data creation to model deployment, with a focus on fairness, transparency, and equity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Deep Into Historical and Societal Dimensions\n",
    "\n",
    "#### Key Question: What Shapes AI Biases?\n",
    "- **AI as a Neutral Tool**: AI reflects biases when it interacts with biased data. Societal prejudices, historical inaccuracies, and sampling biases are often embedded in data, causing AI systems to replicate these imperfections.\n",
    "  \n",
    "#### Medical Biases Rooted in Racial Disparities:\n",
    "1. **Race-Centric Medical Approach**: \n",
    "   - Many racial biases in medicine lack scientific rationale and have led to errors, such as skewed clinical trials and unequal treatment protocols.\n",
    "  \n",
    "#### Real-World Implications of AI Biases in Healthcare:\n",
    "1. **Underrepresentation in Clinical Trials**:\n",
    "   - Historically, racial and ethnic minorities have been underrepresented in clinical trials.\n",
    "   - **Impact**: Drugs and treatments developed from these trials may not benefit all populations equally.\n",
    "   - These clinical trial results inform AI models, which can perpetuate healthcare disparities through clinical decision support systems.\n",
    "\n",
    "2. **Use of Race and Ethnic Correction Factors in Medical AI**:\n",
    "   - The inclusion of race in AI models is controversial:\n",
    "     - **Reinforces Biases**: Racial adjustments can perpetuate historical inequities.\n",
    "     - **Lacks Biological Basis**: Race is often used without scientific validity.\n",
    "     - **Overgeneralization**: Race-based corrections may lead to stereotypical assumptions.\n",
    "   - **Result**: These corrections can lead to differential care and widen health disparities.\n",
    "\n",
    "#### Ethical Considerations:\n",
    "- The use of race in AI needs careful evaluation, as hard-coded attributes like race may contribute to biased outcomes, further exacerbating existing healthcare inequities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race-Based Medicine and Race-Aware Approach\n",
    "\n",
    "#### What is Race-Based Medicine?\n",
    "- **Definition**: Medical practices that use racial or ethnic identity in diagnosing or treating conditions, even when no biological evidence supports the consideration of race.\n",
    "- **Historical Focus**: Based on perceived differences in disease prevalence among racial groups, which has led to flawed medical practices.\n",
    "\n",
    "#### Key Examples of Race-Based Medicine:\n",
    "1. **Kidney Disease and eGFR**:\n",
    "   - **eGFR (Estimated Glomerular Filtration Rate)**: Historically adjusted for race, assuming that black patients naturally have higher creatinine levels.\n",
    "   - **Impact**: This adjustment delayed diagnosis for black patients, often leading to more severe disease at the time of diagnosis and reducing their chances of being placed on kidney transplant waitlists.\n",
    "\n",
    "2. **Vaginal Births After Cesarean (VBAC) Calculator**:\n",
    "   - **VBAC Risk Assessment**: Historically, the calculator included race, assuming that black patients faced higher risks after a cesarean birth.\n",
    "   - **Impact**: This led to overestimated risks for black and Hispanic women, limiting their treatment options and skewing medical recommendations.\n",
    "\n",
    "#### Emerging Approaches to Ethical AI and Algorithmic Fairness in Healthcare:\n",
    "- **Race-Blind Algorithms?**: Simply removing race from all algorithms is not a comprehensive solution. While appealing, it may overlook legitimate health outcome differences.\n",
    "  \n",
    "- **Race-Aware Approach**: \n",
    "   - A **race-aware** perspective contextualizes race by incorporating social determinants of health, systemic biases, and access to healthcare without reinforcing racial biases.\n",
    "   - **Examples**: Socioeconomic factors, environmental conditions, and healthcare access, which often correlate with race, are included in the analysis to ensure fairness without ignoring the reality of health disparities.\n",
    "\n",
    "#### Key Revisions in Medical Practice:\n",
    "1. **eGFR Adjustment Removal**:\n",
    "   - **2021 Change**: The race adjustment for eGFR was eliminated.\n",
    "   - **Kidney Allocation System Revisions**: The new system now accounts for dialysis time, recognizing that black and Hispanic patients often spent more time on dialysis.\n",
    "   - **Impact**: Decreased waitlisting disparities between black and white patients, promoting equity in kidney transplantation.\n",
    "\n",
    "2. **VBAC Calculator Revision**:\n",
    "   - **Recent Update**: The VBAC calculator removed race as a variable, acknowledging that it was used as a proxy for conditions like chronic hypertension.\n",
    "   - **Impact**: More accurate risk assessments for all racial groups, contributing to a more equitable healthcare landscape.\n",
    "\n",
    "#### Conclusion:\n",
    "- **Balanced Approach**: Ethical AI in healthcare should not ignore race entirely but must integrate factors such as social and systemic determinants to ensure fairness. These race-aware revisions have demonstrated significant reductions in healthcare disparities and promote a more equitable medical system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Mitigation Strategies\n",
    "\n",
    "#### Fundamental Bias Evaluation Approaches:\n",
    "1. **Removal of Protected Attributes**:\n",
    "   - A strategy to remove sensitive information like race, gender, or ethnicity from the model's inputs to reduce bias in predictions.\n",
    "   \n",
    "2. **Classification Parity**:\n",
    "   - Ensures that the model performs equally well across different groups, maintaining fairness in metrics like accuracy, precision, and recall for each group.\n",
    "\n",
    "3. **Calibration**:\n",
    "   - Ensures that model predictions are accurate and reflect true probabilities for different groups. This technique checks if predicted outcomes correspond to actual outcomes across various populations.\n",
    "\n",
    "#### Emerging Approaches:\n",
    "1. **Counterfactual Fairness**:\n",
    "   - **Definition**: Ensures that a model's predictions remain fair if protected attributes (e.g., race, gender) are altered in hypothetical scenarios.\n",
    "   - **Example**: Evaluating a depression predictor for cancer patients:\n",
    "     - **Scenario**: Two patients, Alex and Bob, diagnosed with cancer. The model predicts Alex is more likely to suffer from depression than Bob.\n",
    "     - **Counterfactual Test**: Change Alex's gender from female to male while keeping other features constant. If the prediction remains the same, the model is counterfactually fair; if it changes, the model may be biased.\n",
    "   - **Model Agnostic Approach**: Focuses solely on input-output relationships without considering the model’s internal workings.\n",
    "\n",
    "2. **Adversarial Networks**:\n",
    "   - **Goal**: Reduce bias by introducing a **fairness adversary** in training to prevent sensitive attributes from influencing predictions.\n",
    "   - **How it works**: \n",
    "     - During training, a **discriminator** (a neural network) examines hidden representations to detect information leakage related to sensitive attributes (e.g., race or gender).\n",
    "     - The **main model** tries to minimize this leakage while maintaining predictive performance.\n",
    "   - **Adversarial Training Process**:\n",
    "     1. **Step 1**: The main model (e.g., a classifier) makes predictions based on input data.\n",
    "     2. **Step 2**: The discriminator attempts to predict sensitive attributes from the main model’s hidden representations.\n",
    "     3. **Adversarial Loss**: The main model minimizes this loss to ensure that sensitive attributes do not influence its predictions, thus promoting fairness.\n",
    "   - **Impact**: Adversarial training helps the model focus on relevant medical factors instead of potentially biased or sensitive attributes.\n",
    "\n",
    "#### Conclusion:\n",
    "Counterfactual fairness and adversarial networks offer advanced methods for mitigating biases in AI models, ensuring fairness across sensitive attributes. These approaches complement traditional strategies like removing protected attributes, ensuring classification parity, and calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative AI, Medicine and Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Potentials and Ethical Quandaries\n",
    "\n",
    "#### Introduction:\n",
    "- **Generative AI** refers to models that learn data patterns and generate new data, distinct from traditional machine learning.\n",
    "- **Healthcare Applications**: Generative AI can create synthetic medical records for research, offering privacy-safe data generation.\n",
    "\n",
    "#### Challenges in Generative AI for Healthcare:\n",
    "- **Scale and Complexity**: These models are trained on massive datasets with billions of parameters, requiring significant computational resources and skill.\n",
    "- **Bias Absorption**: Generative models learn from data holistically, including inherent biases, such as racial or historical biases.\n",
    "- **Impact on Underrepresented Groups**: Models may perform worse for underrepresented groups if the training data is skewed toward certain populations, raising concerns about fairness.\n",
    "\n",
    "#### Bias Mitigation Strategies:\n",
    "1. **Corrective Use of Generative AI**:\n",
    "   - Generative AI can be trained to counteract systemic biases, creating opportunities for a more equitable healthcare system.\n",
    "   \n",
    "2. **Validation and Quality Checks**:\n",
    "   - Generative AI models require the same bias mitigation strategies as other AI models:\n",
    "     - **Validation on independent datasets**.\n",
    "     - **Diversity assessments**.\n",
    "     - **Human-in-the-loop evaluations**: Qualitative feedback from users interacting with the model is critical for understanding its fairness and accuracy beyond quantitative metrics.\n",
    "\n",
    "3. **Prompt Engineering**:\n",
    "   - A technique used to guide the behavior of generative models by crafting specific prompts.\n",
    "   - **Ethical Considerations**: Language choices in prompts can introduce biases, requiring careful design to avoid unintended consequences in the model's outputs.\n",
    "\n",
    "#### Adversarial Training in Generative AI:\n",
    "- **Adversarial Prompts**:\n",
    "   - Used to challenge the model during training by targeting biases and vulnerabilities through intentionally biased prompts.\n",
    "- **Adversarial Loss Function**:\n",
    "   - A loss function is defined to penalize biased outputs, pushing the model to reduce undesired behaviors.\n",
    "- **Iterative Training**:\n",
    "   - Continuous evaluation of the model on both standard and adversarial examples ensures robustness and minimizes susceptibility to biases.\n",
    "\n",
    "#### Conclusion:\n",
    "Adversarial training is a proactive approach to improving fairness in generative AI. By using adversarial examples and refining models iteratively, we create powerful, ethical AI systems that address the challenges of bias and ensure equitable outcomes across diverse populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dismantling Race-Based Medicine\n",
    "\n",
    "#### Introduction:\n",
    "- **Comprehensive Reform Needed**: AI biases and race-based medicine in the US healthcare system require systemic reform.\n",
    "- **Key Dimensions**: Personalized medicine, precision medicine, and precision care are pivotal in promoting equity.\n",
    "\n",
    "#### Increasing Diversity in Clinical Trials:\n",
    "- **Historical Underrepresentation**: Racial and ethnic minorities have been underrepresented in clinical trials, leading to biased guidelines and algorithms.\n",
    "- **Involving Minority Communities**: Actively involving these communities in trial design fosters trust and ensures more representative health data.\n",
    "  \n",
    "#### Personalized and Precision Medicine:\n",
    "- **Personalized Medicine**: Aims to provide treatments tailored to disease and demographic variations, ensuring accurate prevention, diagnosis, and treatment for specific groups.\n",
    "- **Precision Medicine**: Focuses on genetic distinctions for individualized treatment, deepening the approach to healthcare.\n",
    "\n",
    "#### Precision Care as a Catalyst for Equity:\n",
    "- **Holistic Approach**: Precision care addresses not just biological traits, but also the patient’s care goals, social context, and values.\n",
    "- **Reducing Disparities**: By addressing social determinants of health (SDOH), precision care plays a central role in reducing health disparities and dismantling race-based medicine.\n",
    "\n",
    "#### Role of AI in Precision Care:\n",
    "- **AI-Driven Insights**: AI enhances precision care by analyzing large datasets to reveal hidden patterns affecting health outcomes.\n",
    "- **Advancing Equity**: AI helps provide tailored treatments and contributes to a more comprehensive understanding of factors influencing patient health.\n",
    "\n",
    "#### Promoting Education and Awareness:\n",
    "- **Rejecting Simplified Assumptions**: Educating healthcare professionals, researchers, and the public on the complex interplay of race, SDOH, and health disparities is crucial.\n",
    "- **Addressing Racism**: Understanding the role of racism in shaping health outcomes helps dismantle biased healthcare practices.\n",
    "\n",
    "#### Culturally Responsive Care:\n",
    "- **Comprehensive Data Collection**: Guidelines and policies should enhance the collection of data on environmental and social factors impacting health.\n",
    "- **Integrating SDOH**: Incorporating SDOH into routine medical records empowers healthcare providers to address the unique needs of diverse populations, fostering inclusivity.\n",
    "\n",
    "#### Conclusion:\n",
    "By promoting diversity in clinical trials, integrating AI-driven precision care, enhancing education, and focusing on social determinants, the healthcare system can move towards more equitable and inclusive care, effectively dismantling race-based medicine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying AI into Healthcare\n",
    "\n",
    "#### Introduction:\n",
    "- **Generative AI's Popularity in Healthcare**: While generative AI, including large language models (LLMs) like ChatGPT, has gained traction in medicine for tasks such as clinical documentation, decision support, and patient communication, challenges persist in transitioning from tech demos to real-world healthcare applications.\n",
    "\n",
    "#### Potential Uses in Medicine:\n",
    "- **Applications**: Simplifying radiology reports, extracting information from medical records, summarizing medical dialogues, answering patient queries, and assisting with medical coding.\n",
    "- **Capabilities Beyond Training**: Despite being trained to predict word sequences, models like GPT-3 show skills in summarization and answering questions without explicit training.\n",
    "\n",
    "#### Ethical Considerations:\n",
    "- **Patient Privacy & Data Security**: With sensitive medical data involved, privacy and security frameworks need to safeguard against unauthorized access and breaches.\n",
    "- **Bias Mitigation**: Addressing biases in training data is critical to avoid disparities in AI’s impact on various demographic groups. Regular monitoring of AI performance is essential.\n",
    "- **Transparency**: Clear communication about data use, patient consent, and AI’s role in clinical decisions builds trust in AI-integrated systems.\n",
    "\n",
    "#### Regulatory Challenges:\n",
    "- **Interpretability & Fairness**: The complexity of LLMs with billions of parameters introduces issues regarding transparency and fairness in healthcare applications.\n",
    "- **Accountability & Legal Responsibility**: In cases of AI-related harm, responsibility must be clearly allocated, raising questions about the roles of the hospital, patient, and AI developers like OpenAI.\n",
    "- **Real-Time Adaptation & Societal Impact**: The dynamic nature of AI technology demands continuous regulatory evaluation to adapt to real-time healthcare needs.\n",
    "\n",
    "#### Privacy & Security Concerns:\n",
    "- **Sensitive Data Handling**: AI's need for large datasets amplifies the risk of data breaches and reidentification. Robust encryption, access controls, and routine vulnerability assessments are necessary.\n",
    "- **Informed Consent**: Transparent communication with patients about how their data is used and stored is essential to maintain trust.\n",
    "\n",
    "#### Humanistic & Ethical Approaches:\n",
    "- **AI as a Complement**: Generative AI should enhance, not replace, human expertise. Healthcare professionals must balance AI recommendations with empathetic patient care.\n",
    "- **Disclosure & Communication**: Honesty about AI’s involvement in treatment plans and its limitations is critical for maintaining patient trust.\n",
    "\n",
    "#### Regulatory Recommendations:\n",
    "- **New Regulatory Framework**: A distinct category for generative AI in healthcare is needed, as it differs from traditional medical AI technologies.\n",
    "- **FDA-like Oversight Model**: A regulatory approach similar to the FDA’s digital health pre-certification program, focusing on developers of LLMs rather than each iteration, could help streamline oversight while maintaining ethical standards.\n",
    "- **Balance Innovation & Ethics**: Regulatory frameworks should foster innovation while ensuring responsible use, focusing on patient welfare, transparency, and equity in healthcare applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
