{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning clinical data into something you can analyze\n",
    "\n",
    "To define the unit of analysis, we typically refer to the basic entity on which measurements are taken. In your case, the unit of analysis could be an individual patient. Each row in the patient feature matrix would represent a single patient, while each column represents specific clinical features or measurements taken from that patient, such as demographic details, lab results, diagnoses, and treatments.\n",
    "\n",
    "The key considerations for constructing this matrix include:\n",
    "\n",
    "1. **Feature Selection**: Deciding which clinical variables to include—such as comorbidities, vital signs, medications, lab values, or outcomes—is critical. Feature selection often depends on the clinical question. If there are too many features, dimensionality reduction methods, like principal component analysis (PCA) or feature selection algorithms, can help reduce complexity.\n",
    "\n",
    "2. **Handling Missing Data**: Clinical data frequently has missing values. Strategies such as imputation, where missing values are estimated using statistical methods (e.g., mean, median, or predictive modeling), or more sophisticated methods like multiple imputation, are often used to address this issue.\n",
    "\n",
    "3. **Normalization and Scaling**: Since clinical data may come in different units (e.g., weight in kg, glucose levels in mg/dL), standardization or normalization ensures that all features are on a comparable scale, reducing bias in models that depend on distance metrics (like k-NN or SVMs).\n",
    "\n",
    "4. **Impact of Feature Transformation on Analysis**: The way data is transformed (e.g., through log transformations, binning, or one-hot encoding) can directly affect the outcome of the analysis. Certain transformations may emphasize different patterns or associations that answer clinical questions more accurately.\n",
    "\n",
    "In terms of using curated biomedical knowledge, **Knowledge Graphs** and **ontologies** can be essential tools for feature extraction. They can help:\n",
    "\n",
    "- **Map clinical data to standard concepts**: These graphs provide a structured way to categorize conditions, treatments, and outcomes. For example, different clinical codes (ICD-10, SNOMED) can be linked to broader concepts in a Knowledge Graph.\n",
    "- **Support feature generation**: They can help derive new features by linking symptoms or diagnoses to higher-level disease categories or treatment pathways, enabling the use of clinically meaningful groupings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the unit of analysis\n",
    "\n",
    "#### **1. Unit of Observation and Analysis**\n",
    "- **Patient (default unit)**: Most clinical studies focus on the patient as the unit of analysis, meaning each row in the data matrix represents one patient. \n",
    "- **Other units**: Depending on the clinical question, different units might be more appropriate. For example:\n",
    "   - **Drug-Disease Pairs**: For research on off-label medication use, rows could represent pairs of drugs and diseases, with features capturing relationships such as:\n",
    "     - Frequency of drug and disease co-occurrence.\n",
    "     - Temporal proximity of drug mention to diagnosis.\n",
    "   - **Events**: For temporal analyses, each row could represent a specific clinical event (e.g., hospital admission, medication prescription).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Feature Selection**\n",
    "- **Types of features**:\n",
    "   - **Demographics**: Age, sex, ethnicity.\n",
    "   - **Clinical measurements**: Lab values, vital signs.\n",
    "   - **Medications**: Drug names, dosages, duration.\n",
    "   - **Diagnoses**: Disease codes (ICD-10, SNOMED), comorbidities.\n",
    "   - **Outcomes**: Mortality, hospitalization, adverse events.\n",
    "- **Dimensionality reduction**:\n",
    "   - **Too many features** can overwhelm analysis and models. Use:\n",
    "     - **Principal Component Analysis (PCA)**: Reduces feature space while retaining variability.\n",
    "     - **Feature selection algorithms**: Use techniques like Lasso (L1 regularization) or tree-based feature selection (e.g., Random Forest) to retain only the most important features.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Handling Missing Data**\n",
    "- **Nature of missing data**: Often occurs due to incomplete records, data entry errors, or varying follow-up times.\n",
    "- **Imputation strategies**:\n",
    "   - **Mean/median imputation**: Replace missing values with average values.\n",
    "   - **Predictive imputation**: Use models to predict missing values based on other features.\n",
    "   - **Multiple imputation**: Create several datasets with imputed values and average results from each to account for uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Data Transformation and Normalization**\n",
    "- **Normalization**: Ensures all features have the same scale (important for models that depend on distance metrics). Techniques include:\n",
    "   - **Min-Max scaling**: Scales data between 0 and 1.\n",
    "   - **Z-score normalization**: Centers data around a mean of 0 with a standard deviation of 1.\n",
    "- **Transformation methods**:\n",
    "   - **Log transformation**: Compresses large differences between high values, useful for skewed data.\n",
    "   - **Binning**: Group continuous variables into discrete categories (e.g., age groups).\n",
    "   - **One-hot encoding**: Converts categorical variables into binary columns (e.g., yes/no for comorbidities).\n",
    "- **Impact of transformation**: Data transformations can influence the analysis outcome. Some models are more sensitive to certain transformations, so consistency and interpretation must be considered.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Role of Curated Biomedical Knowledge (Knowledge Graphs & Ontologies)**\n",
    "- **Knowledge Graphs**: Structured frameworks that connect clinical terms, helping to organize and classify features.\n",
    "   - **ICD-10** and **SNOMED** codes can be mapped to higher-level disease categories, improving interpretability.\n",
    "- **Ontology-based feature generation**:\n",
    "   - **Grouping concepts**: Conditions, symptoms, and treatments can be grouped under broader categories for simplified analysis (e.g., hypertension and hyperlipidemia under cardiovascular diseases).\n",
    "   - **Hierarchical relationships**: Use ontologies to connect related conditions, symptoms, and treatments.\n",
    "\n",
    "---\n",
    "\n",
    "### **Important Notes for Exam**\n",
    "- **Unit of observation**: Most studies use the patient, but alternative units (e.g., drug-disease pairs) should be considered based on the research question.\n",
    "- **Feature selection**: Choose clinically relevant features; reduce dimensionality when necessary.\n",
    "- **Missing data**: Common in clinical datasets; handle using imputation techniques.\n",
    "- **Data transformation**: Apply normalization and encoding based on the type of analysis.\n",
    "- **Knowledge Graphs**: Essential for mapping clinical data to standard concepts and extracting meaningful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using features and the presence of features\n",
    "\n",
    "#### **1. Feature Inclusion**\n",
    "- **Start with all features**: Begin by including all available features, as modern machine learning models can automatically reduce feature sets by identifying and removing those that do not contribute to model accuracy.\n",
    "- **Handling constraints**: If computing resources are limited, consider reducing the number of features based on computational needs.\n",
    "- **Sensitive features**: In some cases, sensitive information like HIV status may need to be removed to protect patient privacy.\n",
    "\n",
    "#### **2. Implicit Features & Metadata**\n",
    "- **Metadata**: Data that refers to other data can be very informative. For example:\n",
    "   - **Lab test orders vs. results**: The number of times a test (e.g., glucose test) is ordered can hint at a patient’s condition (e.g., diabetes) even if the results are unavailable.\n",
    "   - **Indicator variables**: Use metadata like the occurrence of a test as an indicator of patient conditions (e.g., diabetic status based on frequent glucose-related tests).\n",
    "   - **Example**: A patient having 80% of their lab tests related to glucose measurement might suggest they are diabetic. This feature is derived from the **count of lab test orders** rather than the test results.\n",
    "- **Feature engineering**: Many features are crafted using **prior knowledge** of the disease and its indicators. For example:\n",
    "   - Understanding that diabetes is related to glucose levels helps in crafting features related to glucose test frequency.\n",
    "   - Features can also be **learned computationally** through advanced machine learning methods.\n",
    "\n",
    "#### **3. Feature Engineering in Practice**\n",
    "- **Modern applications**: In risk prediction models, the median number of features used was 27, with a median sample size of 12,000 (2017 study). This highlights the possibility that real-world datasets may use fewer features than often expected in big data discussions.\n",
    "- **Creating advanced feature sets**: You can move beyond standard models by incorporating subtle metadata and implicit indicators to improve the predictive power of your analysis-ready datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create features from structured sources\n",
    "\n",
    "#### **1. Structured Data in Healthcare**\n",
    "- **Common Data Sources**: Healthcare data is often drawn from structured sources such as databases and tables.\n",
    "- **Main Steps in Working with Structured Data**:\n",
    "  - **Accessing Data**: Use SQL (Structured Query Language) to query databases and load results into programming languages like Python for analysis.\n",
    "  - **Standardizing Features**: Ensure consistency in how features (e.g., lab results, diagnoses) are represented, using uniform formats and units.\n",
    "  - **Handling Too Many Features**: If the number of features becomes overwhelming, reduce dimensionality through feature selection techniques.\n",
    "  - **Dealing with Missing Data**: Address missing values using imputation or other methods.\n",
    "  - **Constructing New Features**: Create new features using metadata or derived information (e.g., test order counts).\n",
    "\n",
    "#### **2. Database Operations**\n",
    "- **Joins**: Data from different tables can be linked using a \"join\" operation in SQL, aligning the data based on a unique identifier (e.g., patient ID).\n",
    "\n",
    "#### **3. Data Reshaping**\n",
    "- **Reshaping**: Data may need to be transformed or reshaped into a usable format for analysis, particularly when combining data from multiple sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing features\n",
    "\n",
    "#### **1. Importance of Standardization**\n",
    "- **Standardizing (or Normalizing)**: Transforms features so they share a common numerical range, reducing the effect of extreme values and ensuring consistent scale across features.\n",
    "- **Why it matters**: When features have different scales, analysis methods that rely on distance metrics (e.g., k-NN, clustering) may produce biased or incorrect results.\n",
    "\n",
    "#### **2. Common Standardization Techniques**\n",
    "- **Min-Max Scaling**: Rescales each feature to a specific range, typically **0 to 1**. Formula:\n",
    "  $$\n",
    "  X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "  $$\n",
    "- **Z-score Standardization**: Adjusts data so that each feature has an **arithmetic mean of 0** and a **standard deviation of 1**. Formula:\n",
    "  $$\n",
    "  Z = \\frac{X - \\mu}{\\sigma}\n",
    "  $$\n",
    "  - Where $\\mu$ is the mean and $\\sigma$ is the standard deviation of the feature.\n",
    "\n",
    "#### **3. Benefits of Standardization**\n",
    "- **Facilitates analysis**: Helps models treat each feature equally, especially when working with algorithms that assume features are on a comparable scale.\n",
    "- **Prevents bias**: By transforming the data, it avoids situations where large numbers in certain features disproportionately influence the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with too many features\n",
    "\n",
    "#### **1. Reasons for Not Using All Features**\n",
    "- **Useless Features**: Features that don’t provide valuable information, such as the number of times a record was accessed.\n",
    "- **Missingness**: Features that are missing for most patients can be problematic and may need removal.\n",
    "- **Sparsity**: Features with many missing values for a given patient may be unhelpful.\n",
    "- **Redundancy**: Highly correlated features (e.g., Feature1 and Feature2) can cause issues in analyses that don’t handle correlations well.\n",
    "- **Speed of Analysis**: A large number of features can slow down analysis and may be constrained by computational resources.\n",
    "- **Privacy**: More features can increase the risk of violating patient privacy, making it easier to identify individuals.\n",
    "\n",
    "#### **2. Feature Removal Criteria**\n",
    "- **Constant Features**: Features with the same value for all patients or those that are nearly constant over time should be removed.\n",
    "- **Low Prevalence Features**: Features missing for most patients are challenging to infer and may be candidates for removal.\n",
    "- **Domain Knowledge Aggregation**: Combine features using domain knowledge. For example:\n",
    "  - **Drug Classification**: Aggregate specific drug names into broader categories like NSAIDs.\n",
    "  - **Disease Aggregation**: Group diseases into categories to simplify analysis and improve cross-site comparisons.\n",
    "\n",
    "#### **3. Methods for Feature Reduction**\n",
    "- **Knowledge Graphs**: Use domain knowledge graphs to aggregate and simplify features, making cross-site comparisons easier. Accurate representation of medical knowledge is crucial for effective aggregation.\n",
    "- **Mathematical Techniques**:\n",
    "  - **Principal Component Analysis (PCA)**: A method that uses linear algebra to combine features and detect patterns, independent of specific medical knowledge. This can be useful but may lead to less interpretable derived features.\n",
    "  \n",
    "#### **4. Considerations for Feature Reduction**\n",
    "- **Relevance to Research Question**: Assess if detailed distinctions (e.g., drug brand names) are necessary, or if broader categories (e.g., drug class) will suffice.\n",
    "- **Model Flexibility**: Models like regression may benefit more from feature aggregation than models with higher flexibility (e.g., gradient boosting).\n",
    "- **Computational Efficiency**: Reducing the number of features can improve computational efficiency and is beneficial regardless of the model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The origins of missing values\n",
    "\n",
    "#### **1. Understanding Missing Data**\n",
    "- **Definition**: In a patient feature matrix, missing data can imply:\n",
    "  - **Genuine Absence**: The value should have been recorded but was not.\n",
    "  - **Artifact of Tabular Representation**: The absence of data may result from the structure of the matrix (e.g., disease codes columns being empty for patients without those diseases).\n",
    "  - **Deliberate Non-Collection**: The value might not be relevant for all patients, indicating that missing data is intentional (e.g., a specific test not administered to all patients).\n",
    "\n",
    "#### **2. Implications of Missing Data**\n",
    "- **Data Reporting**:\n",
    "  - **Special Markers**: Systems often use special values (e.g., NA, Null) to denote missing data. Numerical values outside the expected range (e.g., -999, 0) may also be used, but these need proper documentation.\n",
    "  - **Interpretation**: Ensure that markers are clearly documented to distinguish between actual missing data and recorded zero values.\n",
    "\n",
    "- **Impact on Analysis**:\n",
    "  - **Bias from Removal**: Removing records with missing values can lead to biased results. For example, homeless diabetic patients might have more missing lab values but are also at higher risk for other conditions. Excluding these patients could under-represent important groups and skew results.\n",
    "  - **Imputation**: Replacing missing values (imputation) needs to be handled carefully to avoid introducing biases or inaccuracies.\n",
    "\n",
    "#### **3. Strategies for Handling Missing Data**\n",
    "- **Documentation**: Clearly document how missing data is represented and handled in your dataset to avoid misinterpretation.\n",
    "- **Consider Impact**: Evaluate how missing data might affect your analysis, particularly regarding biases and under-representation of certain groups.\n",
    "- **Imputation Techniques**:\n",
    "  - Use statistical methods to estimate missing values, but ensure these methods are appropriate for your data and research question.\n",
    "  - Consider domain knowledge to guide imputation strategies and avoid misleading conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values\n",
    "\n",
    "#### **1. Imputation Overview**\n",
    "- **Definition**: Imputation involves predicting and filling in missing values based on other information in the dataset, rather than simply removing records with missing data.\n",
    "\n",
    "#### **2. Common Imputation Methods**\n",
    "\n",
    "- **Column-Mean Imputation**:\n",
    "  - **Description**: Replaces missing values with the mean (average) of the known values in the same column.\n",
    "  - **Limitations**: Assumes that values in other rows of the same column provide relevant information about the missing value. This may not always be valid, especially in medical datasets where individual variations are significant.\n",
    "\n",
    "- **Using Other Columns**:\n",
    "  - **Description**: Improves imputation by considering values in other columns of the same patient. For instance, using known age and weight to estimate height.\n",
    "  - **Advantage**: Accounts for correlations among different features of the same patient, providing a more informed estimate.\n",
    "\n",
    "- **k-Nearest Neighbors (k-NN) Imputation**:\n",
    "  - **Description**: Fills in missing values by finding patients similar to the current patient based on other features and using those patients' values to impute the missing one.\n",
    "  - **Advantage**: Utilizes the similarity between patients to make more accurate predictions.\n",
    "\n",
    "- **Multiple Imputation**:\n",
    "  - **Description**: Repeatedly performs imputation to create several different versions of the dataset, each with different imputed values. Analyzing these multiple datasets helps estimate the variance or imprecision of the imputed values.\n",
    "  - **Advantage**: Provides a measure of uncertainty around the imputed values, improving the robustness of the analysis.\n",
    "\n",
    "#### **3. Considerations for Imputation**\n",
    "- **Data Characteristics**: Choose an imputation method based on the nature of the data and the relationships among features.\n",
    "- **Impact on Analysis**: Be aware of how imputation affects the results and interpret findings with an understanding of the imputation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary recommendations for missing values\n",
    "\n",
    "#### **1. General Guidance**\n",
    "- **Imputation**:\n",
    "  - **When to Consider**: If a variable has only a few missing values, imputation is often appropriate.\n",
    "  - **Why**: Imputation can provide more information and maintain the integrity of the dataset.\n",
    "\n",
    "- **Removal**:\n",
    "  - **When to Consider**: If a variable has mostly missing values, removing it might be preferable.\n",
    "  - **Why**: Imputing values for most patients in such cases can be complex and may not provide useful information.\n",
    "\n",
    "- **Middle Ground**:\n",
    "  - **Unclear Cases**: For variables with a moderate amount of missing data, there is no one-size-fits-all solution. Consulting with experts is advisable.\n",
    "  - **Indicator Variables**: Some suggest adding indicator variables to denote imputed values, but this can significantly increase the feature space and is subject to debate.\n",
    "\n",
    "#### **2. Practical Considerations**\n",
    "- **Imputation Challenges**:\n",
    "  - **Complexity**: Imputation methods can be complex and make assumptions about the data that may not always hold true.\n",
    "  - **Sparse Data**: High levels of missing data make imputation more challenging and less reliable.\n",
    "\n",
    "- **Alternative Methods**:\n",
    "  - **Analysis Methods**: Some methods, like classification trees, can handle missing data inherently, reducing the need for imputation.\n",
    "  - **Practicality**: The benefits of imputation in terms of accuracy improvements should be weighed against the computational costs and complexity.\n",
    "\n",
    "#### **3. Key Questions to Consider**\n",
    "- **Importance of Feature**: Assess how crucial the feature with missing data is to your analysis. Can the research question be answered without it?\n",
    "- **Imputation vs. Removal**: Determine if imputation adds value or if the feature can be dropped without significantly impacting the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "A colleague comes to you with a dataset for diabetic patients. The dataset contains patient’s latest blood sugar levels, the doses of their diabetes medications, and the number of diabetes-related visits the patient has had in the past year. She wants to use this data to predict patient survival, but she is concerned because 50% of the patients have no recorded value for blood sugar level. Another colleague recommends column mean imputation. \n",
    "\n",
    "Do you agree with that recommendation for this dataset?\n",
    "\n",
    "- No, column mean imputation may not be appropriate for blood sugar levels, as individual variations in blood sugar levels are significant and may not be well represented by the mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing new features\n",
    "\n",
    "#### **1. Feature Engineering Overview**\n",
    "- **Definition**: Feature engineering involves creating new features from the original data by applying transformations or combining existing features. This can enhance model performance by making features more informative or robust.\n",
    "\n",
    "#### **2. Benefits of Feature Engineering**\n",
    "- **Improved Performance**: Well-engineered features can lead to better performance of models compared to using raw features.\n",
    "- **Simplicity vs. Complexity**: Simple models with well-engineered features can sometimes outperform complex models with many raw features, particularly in clinical data.\n",
    "\n",
    "#### **3. Example of Feature Engineering**\n",
    "- **Body Mass Index (BMI)**: Calculate BMI from height and weight using a formula. This derived feature can be more useful than height and weight alone in some analyses.\n",
    "- **Binary Variables**: Instead of using raw counts, convert them into binary indicators (e.g., whether a count is greater than one). Binary variables are often more robust to outliers and can simplify analysis.\n",
    "\n",
    "#### **4. Practical Considerations**\n",
    "- **Distinguishing Counts from Indicators**: Decide if the count of occurrences (e.g., number of codes for a procedure) or a binary presence/absence indicator is more meaningful. For instance, does seeing two codes indicate disease severity or reflect a billing practice?\n",
    "- **Simplicity and Robustness**: Simple feature engineering, such as converting counts to binary variables, can often be more robust and easier to interpret.\n",
    "ve features?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of engineered features\n",
    "\n",
    "#### **1. Clinical Scoring Systems**\n",
    "- **Purpose**: Simple formulas that combine various values from electronic medical records (EMRs) to estimate the severity of a patient's condition.\n",
    "- **Example**: Body Mass Index (BMI) - a straightforward scoring system that estimates whether a person is over- or underweight.\n",
    "\n",
    "#### **2. Comorbidity Indices**\n",
    "- **Purpose**: Quantify the overall burden of multiple diseases to account for the overall illness of a patient.\n",
    "- **Examples**:\n",
    "  - **Charlson Comorbidity Index**: Estimates the risk of mortality by considering various comorbid conditions.\n",
    "  - **Elixhauser Comorbidity Index**: Used to assess the impact of comorbidities on hospital outcomes.\n",
    "\n",
    "#### **3. Proxy Features**\n",
    "- **Socioeconomic Status**: Can be inferred from a patient’s zip code and the number of EMR records, scaled by overall health measures.\n",
    "- **Smoking Status**: Inferred from text analysis of keywords (e.g., \"cigarette\") in clinical notes.\n",
    "\n",
    "#### **4. Specific Features from Clinical Knowledge**\n",
    "- **Growth Rate of Wounds**: Defined as the change in wound size per unit time. This feature was created to predict the risk of a wound not healing within three months, significantly improving prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to consider engineered features\n",
    "\n",
    "#### **1. Identifying Gaps in Measurement**\n",
    "- **Determine Important Unmeasured Features**: Consider what features might be relevant but are not directly measured. Construct proxies from existing features if necessary.\n",
    "- **Example**: Wound healing rate as a proxy feature to estimate the risk of non-healing.\n",
    "\n",
    "#### **2. Utilizing Pre-Validated Clinical Scoring Systems**\n",
    "- **Advantages**: Use established scoring systems that have been validated for clinical problems, as they are likely to be effective and reliable.\n",
    "\n",
    "#### **3. Approaches to Feature Construction**\n",
    "- **Counts, Differences, and Ratios**: Consider creating features based on counts, differences between measurements, changes over time, and ratios.\n",
    "- **Clinical Knowledge and Creativity**: Apply clinical insight and creativity to construct meaningful features. Let the downstream analysis help determine which features are most useful.\n",
    "\n",
    "#### **4. Cost-Benefit Analysis**\n",
    "- **Balance Effort and Benefit**: Evaluate the trade-off between the benefits of new features and the effort required to create them.\n",
    "\n",
    "#### **5. Deep Learning Methods**\n",
    "- **Raw Data Processing**: Deep learning methods can learn features directly from raw data without domain knowledge.\n",
    "- **Data Requirements**: These methods require large datasets and are particularly effective for processing signals and images. The benefits for electronic medical records are more modest compared to their impact on signals and images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main points about creating analysis ready datasets\n",
    "\n",
    "#### **1. Transforming Structured Data**\n",
    "- **Data Sources**: Structured data in database tables can be converted into an analysis-ready dataset, also known as the patient feature matrix.\n",
    "- **Tools**: Use widely available programming tools to perform this transformation.\n",
    "\n",
    "#### **2. Reducing the Number of Features**\n",
    "- **Aggregation**: Reduce features by aggregating them using domain knowledge or mathematical techniques.\n",
    "  - **Domain Knowledge**: Group or summarize features based on clinical insights.\n",
    "  - **Mathematical Techniques**: Use methods like Principal Component Analysis (PCA) to handle high-dimensional data.\n",
    "\n",
    "#### **3. Handling Missing Data**\n",
    "- **Options**: Address missing data through removal or imputation.\n",
    "  - **Removal**: Delete records or features with excessive missing values.\n",
    "  - **Imputation**: Apply techniques with varying levels of sophistication to estimate missing values.\n",
    "\n",
    "#### **4. Feature Engineering**\n",
    "- **Creating New Features**: Construct additional features from the original data to enhance analysis.\n",
    "  - **Techniques**: Utilize counts, differences, changes over time, and ratios to generate meaningful features.\n",
    "\n",
    "#### **5. Enhancing Effectiveness**\n",
    "- **Domain Knowledge**: Improve your ability to create and analyze datasets by learning about relevant biology and medicine related to your research question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured knowledge graphs\n",
    "\n",
    "#### **1. What is a Knowledge Graph?**\n",
    "- **Definition**: A knowledge graph, also known as an ontology, is a structured representation of entities within a domain and the relationships among them.\n",
    "- **Purpose**: It provides a comprehensive and digital form of domain knowledge that can be searched and processed by computers.\n",
    "- **Construction**: Building a knowledge graph is labor-intensive but essential for representing complex relationships and concepts.\n",
    "\n",
    "#### **2. Using Knowledge Graphs in Clinical Data**\n",
    "- **Prior Knowledge Integration**: Knowledge graphs help integrate prior knowledge into data analysis. For instance:\n",
    "  - **Example 1**: Using counts of glucose-related lab tests to infer diabetes status instead of relying on actual test results.\n",
    "  - **Example 2**: Grouping drug brand names into broader categories like NSAIDs for better analysis.\n",
    "\n",
    "#### **3. Understanding Domain Concepts**\n",
    "- **Contextual Knowledge**: Knowledge graphs provide information about diseases, tests, and treatments. For example:\n",
    "  - **Diabetes**: The knowledge graph links diabetes to glucose metabolism disorders.\n",
    "  - **Drug Categorization**: Identifies that Aleve contains ibuprofen and belongs to the NSAID category.\n",
    "\n",
    "#### **4. Addressing Synonyms and Variability**\n",
    "- **Standardization**: Knowledge graphs help address variability in clinical data by representing synonyms and different expressions of the same concept.\n",
    "- **Clarity**: They provide a unified view of related terms and entities, making it easier to standardize and interpret clinical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what exactly is in a knowledge graph\n",
    "\n",
    "**Definition and Purpose:**\n",
    "- **Knowledge Graph**: A digital representation of entities within a domain and their interrelationships. Often used interchangeably with the term \"ontology.\"\n",
    "- **Purpose**: Provides structured, comprehensive information about entities and their relationships, enhancing the ability to query and analyze clinical data.\n",
    "\n",
    "**Components of Knowledge Graphs:**\n",
    "1. **Entities**:\n",
    "   - **Examples**: Symptoms, diseases, medications, treatments, body parts.\n",
    "   - **Function**: Represent specific elements within the medical domain.\n",
    "\n",
    "2. **Synonyms and Equivalent Names**:\n",
    "   - **Purpose**: Ensures consistent referencing of entities.\n",
    "   - **Examples**: \"Heart attack\" and \"acute myocardial infarction\"; brand names and generic names of medications.\n",
    "\n",
    "3. **Relations Between Entities**:\n",
    "   - **Common Relation**: \"Is a kind of\" or \"kind of.\"\n",
    "   - **Examples**: \n",
    "     - Diarrhea is a kind of gastrointestinal disease.\n",
    "     - Lipitor is a kind of lipid-lowering drug.\n",
    "   - **Inheritance**: Entities inherit properties from their parent entities (e.g., if Lipitor is a lipid-lowering drug, it shares properties of all lipid-lowering drugs).\n",
    "\n",
    "4. **Links to Other Knowledge Graphs**:\n",
    "   - **Function**: Connects different knowledge graphs to provide a unified reference framework across diverse data sources.\n",
    "   - **Example**: Metformin is linked to its role in treating diabetes.\n",
    "\n",
    "**Applications in Clinical Data Analysis**:\n",
    "- **Enhanced Querying**: Facilitates finding patients with specific conditions or treatments by identifying various terms with the same meaning.\n",
    "- **Example**: Identifying all patients with diabetes or those taking allergy medications by understanding synonyms and relationships.\n",
    "\n",
    "**Benefits**:\n",
    "- **Consistency**: Helps standardize terms and definitions across different datasets.\n",
    "- **Comprehensiveness**: Provides a broad, structured view of medical knowledge, supporting better data analysis and integration.\n",
    "\n",
    "**Challenges**:\n",
    "- **Creation**: Building a knowledge graph is labor-intensive and requires expert knowledge.\n",
    "- **Complexity**: Integrating and maintaining links between different knowledge graphs can be complex.\n",
    "\n",
    "This summary outlines the key elements and uses of knowledge graphs in clinical data analysis, highlighting their importance in structuring and querying medical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are important knowledge graphs\n",
    "\n",
    "**1. International Classification of Diseases (ICD):**\n",
    "   - **Purpose**: Originally created to record causes of death, now used for diagnosing and classifying diseases.\n",
    "   - **Versions**: \n",
    "     - **ICD-10**: Current version in the USA.\n",
    "     - **ICD-9**: Older version, still relevant for historical data.\n",
    "   - **Example Codes**:\n",
    "     - **ICD-9**: 250.00 (Uncomplicated diabetes mellitus type 2).\n",
    "     - **ICD-10**: E11.9 (Type 2 diabetes mellitus without complications).\n",
    "\n",
    "**2. Current Procedural Terminology (CPT):**\n",
    "   - **Purpose**: Categorizes medical procedures and services for billing purposes.\n",
    "   - **Entities**: Procedures, services, and modifiers.\n",
    "   - **Relationship**: Subclass of or kind of.\n",
    "\n",
    "**3. RxNorm:**\n",
    "   - **Purpose**: Provides naming systems for both generic and branded drugs.\n",
    "   - **Features**: Represents synonyms for drugs.\n",
    "   - **Tool**: RXNav, used to navigate RxNorm.\n",
    "\n",
    "**4. Anatomic Therapeutic Chemical (ATC) Classification System:**\n",
    "   - **Purpose**: Categorizes drugs based on their active ingredients, organ systems they act upon, therapeutic activity, and pharmacological properties.\n",
    "   - **Maintainer**: World Health Organization.\n",
    "\n",
    "**5. Logical Observation Identifiers Names and Codes (LOINC):**\n",
    "   - **Purpose**: Provides identifiers for medical laboratory observations and measurements.\n",
    "   - **Maintainer**: Regenstrief Institute.\n",
    "\n",
    "**6. Unified Medical Language System (UMLS) Metathesaurus:**\n",
    "   - **Purpose**: A comprehensive resource combining over 140 knowledge graphs, including ICD, CPT, RxNorm, and more.\n",
    "   - **Features**: Contains declarations of relationships between various knowledge graphs.\n",
    "   - **Components**: Includes the Semantic Network and Lexical Tools.\n",
    "   - **Resource**: Tutorials and materials are available from the US National Library of Medicine.\n",
    "\n",
    "**Additional Resource:**\n",
    "- **BioPortal**: Hosted by the National Center for Biomedical Ontology at Stanford, provides access to various biomedical knowledge graphs.\n",
    "\n",
    "**Applications:**\n",
    "- **Creating Analysis Ready Datasets**: Use knowledge graphs to ensure consistency, identify synonyms, and integrate various data sources.\n",
    "- **Clinical Data Mining**: Essential for querying and analyzing medical data accurately.\n",
    "\n",
    "This summary provides an overview of key knowledge graphs used in medical data analysis, their purposes, and their applications in creating analysis-ready datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose which knowledge graph to use\n",
    "\n",
    "**1. Key Questions for Evaluation:**\n",
    "   - **Entities and Classification**: \n",
    "     - What entities are included in the knowledge graph?\n",
    "     - What is the basis for classifying these entities?\n",
    "     - Understand the meaning and implications of the relationships in the graph (e.g., \"is a kind of\").\n",
    "\n",
    "   - **Naming and Synonyms**:\n",
    "     - What terminology is used to name the entities?\n",
    "     - Are there synonyms, alternative names, or different spellings included?\n",
    "     - Assess how well the graph handles variations in terminology.\n",
    "\n",
    "   - **Mappings and Connectivity**:\n",
    "     - Is the knowledge graph mapped to other knowledge graphs?\n",
    "     - Evaluate how well-connected the graph is with other resources.\n",
    "     - Connectivity can enhance the integration and utility of the knowledge graph.\n",
    "\n",
    "**2. Practical Approaches for Assessment:**\n",
    "   - **Term Coverage**:\n",
    "     - Analyze the number of terms from the knowledge graph mentioned in the textual data from electronic medical records (EMRs).\n",
    "     - Determine the coverage and relevance of the knowledge graph for your dataset.\n",
    "\n",
    "   - **Handling Large Graphs**:\n",
    "     - For large knowledge graphs with millions of terms, use term occurrence counts to filter and select relevant terms.\n",
    "     - Helps in managing and refining the scope of the knowledge graph to suit your needs.\n",
    "\n",
    "   - **Updates and Currency**:\n",
    "     - Knowledge graphs are periodically updated (e.g., UMLS updates quarterly).\n",
    "     - Ensure the knowledge graph you use is current and reflects the latest medical knowledge and classifications.\n",
    "\n",
    "**3. Summary:**\n",
    "   - **Knowledge Graphs**: Large, curated collections of medical entities, their synonyms, and relationships.\n",
    "   - **Utility**: Essential for creating features and processing clinical texts in medical data mining.\n",
    "   - **Recommendation**: If not already familiar with UMLS or other major knowledge graphs, explore these resources for comprehensive and accurate medical knowledge.\n",
    "\n",
    "This framework will help you assess the suitability and utility of different knowledge graphs for clinical data mining, ensuring that the chosen resource aligns with your data and research objectives."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
